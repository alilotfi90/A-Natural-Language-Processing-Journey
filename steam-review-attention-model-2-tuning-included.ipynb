{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOl/25muzsqwFaE8P5dXnTe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alilotfi90/A-Natural-Language-Processing-Journey/blob/main/steam-review-attention-model-2-tuning-included.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu18l0CO9aEx",
        "outputId": "c70b8317-4104-40ad-9907-03c0893e6e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/steam_data_set.zip\" -d \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89e3ar2f9k--",
        "outputId": "0479a8a0-3a95-4acb-db62-05ce458081bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/steam_data_set.zip\n",
            "  inflating: /content/test_gr/test.csv  \n",
            "  inflating: /content/train_gr/game_overview.csv  \n",
            "  inflating: /content/train_gr/train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/train_gr/train.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Explore first few rows of the DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JeIALYP92mI",
        "outputId": "bb5db1cb-953b-4b77-d4c0-3a7f7ab359be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   review_id                        title    year  \\\n",
            "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
            "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
            "2          3  Spooky's Jump Scare Mansion  2016.0   \n",
            "3          4  Spooky's Jump Scare Mansion  2015.0   \n",
            "4          5  Spooky's Jump Scare Mansion  2015.0   \n",
            "\n",
            "                                         user_review  user_suggestion  \n",
            "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
            "1  Best game, more better than Sam Pepper's YouTu...                1  \n",
            "2  A littly iffy on the controls, but once you kn...                1  \n",
            "3  Great game, fun and colorful and all that.A si...                1  \n",
            "4  Not many games have the cute tag right next to...                1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing and Padding\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['user_review'])\n",
        "\n",
        "# Getting vocab size from tokenizer word index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "padded_sequences = pad_sequences(tokenizer.texts_to_sequences(df['user_review']), maxlen=100, padding='post', truncating='post')\n"
      ],
      "metadata": {
        "id": "X6TIbckr95Wk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class AttentionLayer(layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.W1 = layers.Dense(units)\n",
        "        self.W2 = layers.Dense(units)\n",
        "        self.V = layers.Dense(1)\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "awwonE7_-k2M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "embedding_dim = 32\n",
        "max_length = 100\n",
        "\n",
        "input_text = Input(shape=(max_length,))\n",
        "embedding_layer = layers.Embedding(vocab_size, embedding_dim)(input_text)\n",
        "\n",
        "# LSTM layer\n",
        "lstm_out, lstm_hidden, _ = layers.LSTM(256, return_sequences=True, return_state=True)(embedding_layer)\n",
        "\n",
        "# Attention layer\n",
        "attention_layer = AttentionLayer(64)\n",
        "context_vector, attention_weights = attention_layer(lstm_out, lstm_hidden)\n",
        "\n",
        "# Fully connected layers\n",
        "dense_layer = layers.Dense(64, activation='relu')(context_vector)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(dense_layer)\n",
        "\n",
        "\n",
        "model = models.Model(inputs=input_text, outputs=output_layer)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xdUrgeX5-6Rh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['user_suggestion'].values, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model creation\n",
        "input_text = Input(shape=(max_length,))\n",
        "embedding_layer = layers.Embedding(vocab_size, embedding_dim)(input_text)\n",
        "lstm_out, lstm_hidden, _ = layers.LSTM(256, return_sequences=True, return_state=True)(embedding_layer)\n",
        "attention_layer = AttentionLayer(64)\n",
        "context_vector, attention_weights = attention_layer(lstm_out, lstm_hidden)\n",
        "dense_layer = layers.Dense(64, activation='relu')(context_vector)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(dense_layer)\n",
        "model = models.Model(inputs=input_text, outputs=output_layer)\n",
        "\n",
        "#model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Training for different epoch values\n",
        "epoch_list = [5, 10, 20, 40]\n",
        "total_epochs = 0\n",
        "\n",
        "for epochs in epoch_list:\n",
        "    print(f\"\\nTraining for {epochs} epochs...\\n\")\n",
        "\n",
        "    # Training\n",
        "    model.fit(X_train, y_train, epochs=epochs, initial_epoch=total_epochs, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    total_epochs = epochs\n",
        "\n",
        "    # Evaluation\n",
        "    loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "    print(f\"\\nTest accuracy after a total of {epochs} epochs: {accuracy*100:.2f}%\\n\")\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1KDE-lL_hPy",
        "outputId": "cb4996f6-5265-42bb-88dd-70f7a94e31d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training for 5 epochs...\n",
            "\n",
            "Epoch 1/5\n",
            "438/438 [==============================] - 40s 83ms/step - loss: 0.5446 - accuracy: 0.7336 - val_loss: 0.4086 - val_accuracy: 0.8245\n",
            "Epoch 2/5\n",
            "438/438 [==============================] - 12s 28ms/step - loss: 0.3175 - accuracy: 0.8683 - val_loss: 0.3837 - val_accuracy: 0.8317\n",
            "Epoch 3/5\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 0.1947 - accuracy: 0.9267 - val_loss: 0.4589 - val_accuracy: 0.8177\n",
            "Epoch 4/5\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 0.1261 - accuracy: 0.9563 - val_loss: 0.5844 - val_accuracy: 0.8151\n",
            "Epoch 5/5\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 0.0827 - accuracy: 0.9728 - val_loss: 0.5612 - val_accuracy: 0.8062\n",
            "110/110 - 1s - loss: 0.5612 - accuracy: 0.8062 - 668ms/epoch - 6ms/step\n",
            "\n",
            "Test accuracy after a total of 5 epochs: 80.62%\n",
            "\n",
            "\n",
            "Training for 10 epochs...\n",
            "\n",
            "Epoch 6/10\n",
            "438/438 [==============================] - 8s 18ms/step - loss: 0.0568 - accuracy: 0.9804 - val_loss: 0.7363 - val_accuracy: 0.8065\n",
            "Epoch 7/10\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.8371 - val_accuracy: 0.8025\n",
            "Epoch 8/10\n",
            "438/438 [==============================] - 7s 15ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 1.0761 - val_accuracy: 0.7979\n",
            "Epoch 9/10\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.9836 - val_accuracy: 0.8008\n",
            "Epoch 10/10\n",
            "438/438 [==============================] - 7s 16ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 1.3786 - val_accuracy: 0.8008\n",
            "110/110 - 1s - loss: 1.3786 - accuracy: 0.8008 - 660ms/epoch - 6ms/step\n",
            "\n",
            "Test accuracy after a total of 10 epochs: 80.08%\n",
            "\n",
            "\n",
            "Training for 20 epochs...\n",
            "\n",
            "Epoch 11/20\n",
            "438/438 [==============================] - 7s 16ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 1.0980 - val_accuracy: 0.7954\n",
            "Epoch 12/20\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 1.3609 - val_accuracy: 0.7922\n",
            "Epoch 13/20\n",
            "438/438 [==============================] - 7s 16ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.4013 - val_accuracy: 0.7888\n",
            "Epoch 14/20\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 1.5670 - val_accuracy: 0.7914\n",
            "Epoch 15/20\n",
            "438/438 [==============================] - 7s 16ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.5065 - val_accuracy: 0.7997\n",
            "Epoch 16/20\n",
            "438/438 [==============================] - 6s 13ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 1.4593 - val_accuracy: 0.7942\n",
            "Epoch 17/20\n",
            "438/438 [==============================] - 6s 15ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.4254 - val_accuracy: 0.7957\n",
            "Epoch 18/20\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 1.3392 - val_accuracy: 0.7854\n",
            "Epoch 19/20\n",
            "438/438 [==============================] - 6s 13ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.4209 - val_accuracy: 0.7925\n",
            "Epoch 20/20\n",
            "438/438 [==============================] - 7s 15ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 1.6348 - val_accuracy: 0.7934\n",
            "110/110 - 1s - loss: 1.6348 - accuracy: 0.7934 - 540ms/epoch - 5ms/step\n",
            "\n",
            "Test accuracy after a total of 20 epochs: 79.34%\n",
            "\n",
            "\n",
            "Training for 40 epochs...\n",
            "\n",
            "Epoch 21/40\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 1.5930 - val_accuracy: 0.7848\n",
            "Epoch 22/40\n",
            "438/438 [==============================] - 7s 16ms/step - loss: 8.5699e-04 - accuracy: 0.9999 - val_loss: 1.6076 - val_accuracy: 0.7931\n",
            "Epoch 23/40\n",
            "438/438 [==============================] - 5s 12ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 1.7379 - val_accuracy: 0.7922\n",
            "Epoch 24/40\n",
            "438/438 [==============================] - 7s 16ms/step - loss: 1.6984e-04 - accuracy: 0.9999 - val_loss: 1.8724 - val_accuracy: 0.7877\n",
            "Epoch 25/40\n",
            "438/438 [==============================] - 6s 13ms/step - loss: 1.5746e-04 - accuracy: 0.9999 - val_loss: 1.9625 - val_accuracy: 0.7908\n",
            "Epoch 26/40\n",
            "438/438 [==============================] - 7s 16ms/step - loss: 1.5513e-04 - accuracy: 0.9999 - val_loss: 2.0391 - val_accuracy: 0.7885\n",
            "Epoch 27/40\n",
            "438/438 [==============================] - 6s 13ms/step - loss: 1.4834e-04 - accuracy: 0.9999 - val_loss: 2.1103 - val_accuracy: 0.7902\n",
            "Epoch 28/40\n",
            "438/438 [==============================] - 7s 16ms/step - loss: 1.4962e-04 - accuracy: 0.9999 - val_loss: 2.1781 - val_accuracy: 0.7888\n",
            "Epoch 29/40\n",
            "438/438 [==============================] - 6s 13ms/step - loss: 1.5076e-04 - accuracy: 0.9999 - val_loss: 2.2406 - val_accuracy: 0.7891\n",
            "Epoch 30/40\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 1.4874e-04 - accuracy: 0.9999 - val_loss: 2.3012 - val_accuracy: 0.7885\n",
            "Epoch 31/40\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 1.4806e-04 - accuracy: 0.9999 - val_loss: 2.3620 - val_accuracy: 0.7894\n",
            "Epoch 32/40\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 1.5560e-04 - accuracy: 0.9999 - val_loss: 2.4179 - val_accuracy: 0.7914\n",
            "Epoch 33/40\n",
            "438/438 [==============================] - 7s 16ms/step - loss: 1.0733e-04 - accuracy: 0.9999 - val_loss: 2.4946 - val_accuracy: 0.7899\n",
            "Epoch 34/40\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 1.0090 - val_accuracy: 0.7905\n",
            "Epoch 35/40\n",
            "438/438 [==============================] - 7s 15ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 1.1153 - val_accuracy: 0.7919\n",
            "Epoch 36/40\n",
            "438/438 [==============================] - 6s 13ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.5035 - val_accuracy: 0.7937\n",
            "Epoch 37/40\n",
            "438/438 [==============================] - 7s 15ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.7544 - val_accuracy: 0.7874\n",
            "Epoch 38/40\n",
            "438/438 [==============================] - 5s 13ms/step - loss: 3.6836e-04 - accuracy: 0.9999 - val_loss: 1.7172 - val_accuracy: 0.7917\n",
            "Epoch 39/40\n",
            "438/438 [==============================] - 7s 15ms/step - loss: 1.8804e-04 - accuracy: 0.9999 - val_loss: 1.8791 - val_accuracy: 0.7902\n",
            "Epoch 40/40\n",
            "438/438 [==============================] - 6s 14ms/step - loss: 1.5910e-04 - accuracy: 0.9999 - val_loss: 1.9668 - val_accuracy: 0.7894\n",
            "110/110 - 1s - loss: 1.9668 - accuracy: 0.7894 - 823ms/epoch - 7ms/step\n",
            "\n",
            "Test accuracy after a total of 40 epochs: 78.94%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "\n",
        "import kerastuner as kt\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    input_text = Input(shape=(max_length,))\n",
        "    embedding_layer = layers.Embedding(\n",
        "        vocab_size,\n",
        "        hp.Int('embedding_dim', min_value=32, max_value=512, step=32)\n",
        "    )(input_text)\n",
        "    lstm_out, lstm_hidden, _ = layers.LSTM(\n",
        "        hp.Int('lstm_units', min_value=128, max_value=512, step=32),\n",
        "        return_sequences=True,\n",
        "        return_state=True\n",
        "    )(embedding_layer)\n",
        "    attention_layer = AttentionLayer(\n",
        "        hp.Int('attention_units', min_value=32, max_value=128, step=32)\n",
        "    )\n",
        "    context_vector, attention_weights = attention_layer(lstm_out, lstm_hidden)\n",
        "    dense_layer = layers.Dense(\n",
        "        hp.Int('dense_units', min_value=32, max_value=128, step=32),\n",
        "        activation='relu'\n",
        "    )(context_vector)\n",
        "    output_layer = layers.Dense(1, activation='sigmoid')(dense_layer)\n",
        "    model = models.Model(inputs=input_text, outputs=output_layer)\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir',\n",
        "    project_name='helloworld'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "# best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Additional training\n",
        "epoch_list = [5, 10, 15, 20]\n",
        "\n",
        "for epochs in epoch_list:\n",
        "    print(f\"\\nTraining for {epochs} epochs...\\n\")\n",
        "\n",
        "    # Further Training\n",
        "    best_model.fit(X_train, y_train, epochs=epochs, initial_epoch=0, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate model\n",
        "    loss, accuracy = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "    print(f\"\\nTest accuracy after a total of {epochs} epochs: {accuracy*100:.2f}%\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yceShQVPJmon",
        "outputId": "d4770816-39d5-4778-8aab-68fbe11a5fea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 04m 07s]\n",
            "val_accuracy: 0.8347146908442179\n",
            "\n",
            "Best val_accuracy So Far: 0.8428122401237488\n",
            "Total elapsed time: 00h 30m 48s\n",
            "\n",
            "Training for 5 epochs...\n",
            "\n",
            "Epoch 1/5\n",
            "438/438 [==============================] - 44s 89ms/step - loss: 0.2555 - accuracy: 0.8987 - val_loss: 0.3781 - val_accuracy: 0.8362\n",
            "Epoch 2/5\n",
            "438/438 [==============================] - 14s 33ms/step - loss: 0.1320 - accuracy: 0.9521 - val_loss: 0.4669 - val_accuracy: 0.8305\n",
            "Epoch 3/5\n",
            "438/438 [==============================] - 12s 27ms/step - loss: 0.0605 - accuracy: 0.9788 - val_loss: 0.5519 - val_accuracy: 0.8182\n",
            "Epoch 4/5\n",
            "438/438 [==============================] - 10s 23ms/step - loss: 0.0440 - accuracy: 0.9846 - val_loss: 0.8074 - val_accuracy: 0.8217\n",
            "Epoch 5/5\n",
            "438/438 [==============================] - 10s 23ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.7526 - val_accuracy: 0.8165\n",
            "110/110 - 1s - loss: 0.7526 - accuracy: 0.8165 - 752ms/epoch - 7ms/step\n",
            "\n",
            "Test accuracy after a total of 5 epochs: 81.65%\n",
            "\n",
            "\n",
            "Training for 10 epochs...\n",
            "\n",
            "Epoch 1/10\n",
            "438/438 [==============================] - 11s 24ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.8437 - val_accuracy: 0.8065\n",
            "Epoch 2/10\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.9236 - val_accuracy: 0.8005\n",
            "Epoch 3/10\n",
            "438/438 [==============================] - 10s 22ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.9629 - val_accuracy: 0.8102\n",
            "Epoch 4/10\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.8960 - val_accuracy: 0.8082\n",
            "Epoch 5/10\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.2175 - val_accuracy: 0.8119\n",
            "Epoch 6/10\n",
            "438/438 [==============================] - 10s 22ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.2787 - val_accuracy: 0.8119\n",
            "Epoch 7/10\n",
            "438/438 [==============================] - 10s 23ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 1.0637 - val_accuracy: 0.8059\n",
            "Epoch 8/10\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 1.2029 - val_accuracy: 0.8117\n",
            "Epoch 9/10\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.9997 - val_accuracy: 0.8099\n",
            "Epoch 10/10\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 1.2049 - val_accuracy: 0.8111\n",
            "110/110 - 1s - loss: 1.2049 - accuracy: 0.8111 - 853ms/epoch - 8ms/step\n",
            "\n",
            "Test accuracy after a total of 10 epochs: 81.11%\n",
            "\n",
            "\n",
            "Training for 15 epochs...\n",
            "\n",
            "Epoch 1/15\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 1.2297 - val_accuracy: 0.8114\n",
            "Epoch 2/15\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.2773 - val_accuracy: 0.8125\n",
            "Epoch 3/15\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 8.8832e-04 - accuracy: 0.9999 - val_loss: 1.3934 - val_accuracy: 0.8128\n",
            "Epoch 4/15\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 2.8968e-04 - accuracy: 0.9999 - val_loss: 1.4681 - val_accuracy: 0.8114\n",
            "Epoch 5/15\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 4.0721e-04 - accuracy: 0.9998 - val_loss: 1.5276 - val_accuracy: 0.8131\n",
            "Epoch 6/15\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 2.4894e-04 - accuracy: 0.9999 - val_loss: 1.5819 - val_accuracy: 0.8128\n",
            "Epoch 7/15\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 2.2873e-04 - accuracy: 0.9999 - val_loss: 1.6211 - val_accuracy: 0.8122\n",
            "Epoch 8/15\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 2.5515e-04 - accuracy: 0.9999 - val_loss: 1.6653 - val_accuracy: 0.8111\n",
            "Epoch 9/15\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 2.0550e-04 - accuracy: 0.9999 - val_loss: 1.7161 - val_accuracy: 0.8125\n",
            "Epoch 10/15\n",
            "438/438 [==============================] - 9s 22ms/step - loss: 2.5544e-04 - accuracy: 0.9999 - val_loss: 1.7523 - val_accuracy: 0.8131\n",
            "Epoch 11/15\n",
            "438/438 [==============================] - 8s 18ms/step - loss: 2.1943e-04 - accuracy: 0.9999 - val_loss: 1.7928 - val_accuracy: 0.8131\n",
            "Epoch 12/15\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 1.9172e-04 - accuracy: 0.9999 - val_loss: 1.8382 - val_accuracy: 0.8117\n",
            "Epoch 13/15\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 2.0458e-04 - accuracy: 0.9999 - val_loss: 1.8786 - val_accuracy: 0.8119\n",
            "Epoch 14/15\n",
            "438/438 [==============================] - 8s 18ms/step - loss: 1.8640e-04 - accuracy: 0.9999 - val_loss: 1.9396 - val_accuracy: 0.8105\n",
            "Epoch 15/15\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 1.8407e-04 - accuracy: 0.9999 - val_loss: 1.9967 - val_accuracy: 0.8099\n",
            "110/110 - 1s - loss: 1.9967 - accuracy: 0.8099 - 628ms/epoch - 6ms/step\n",
            "\n",
            "Test accuracy after a total of 15 epochs: 80.99%\n",
            "\n",
            "\n",
            "Training for 20 epochs...\n",
            "\n",
            "Epoch 1/20\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 1.3819 - val_accuracy: 0.7905\n",
            "Epoch 2/20\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 0.0275 - accuracy: 0.9901 - val_loss: 0.9008 - val_accuracy: 0.8114\n",
            "Epoch 3/20\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.9951 - val_accuracy: 0.8102\n",
            "Epoch 4/20\n",
            "438/438 [==============================] - 8s 18ms/step - loss: 4.7800e-04 - accuracy: 0.9999 - val_loss: 1.2035 - val_accuracy: 0.8088\n",
            "Epoch 5/20\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 4.7158e-04 - accuracy: 0.9999 - val_loss: 1.2613 - val_accuracy: 0.8057\n",
            "Epoch 6/20\n",
            "438/438 [==============================] - 8s 18ms/step - loss: 2.3634e-04 - accuracy: 0.9999 - val_loss: 1.3083 - val_accuracy: 0.8068\n",
            "Epoch 7/20\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 1.8579e-04 - accuracy: 0.9999 - val_loss: 1.3654 - val_accuracy: 0.8082\n",
            "Epoch 8/20\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 1.7348e-04 - accuracy: 0.9999 - val_loss: 1.4113 - val_accuracy: 0.8071\n",
            "Epoch 9/20\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 1.7634e-04 - accuracy: 0.9999 - val_loss: 1.4545 - val_accuracy: 0.8071\n",
            "Epoch 10/20\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 1.7273e-04 - accuracy: 0.9999 - val_loss: 1.4933 - val_accuracy: 0.8059\n",
            "Epoch 11/20\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 1.7331e-04 - accuracy: 0.9999 - val_loss: 1.5322 - val_accuracy: 0.8062\n",
            "Epoch 12/20\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 1.6597e-04 - accuracy: 0.9999 - val_loss: 1.5685 - val_accuracy: 0.8065\n",
            "Epoch 13/20\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 1.7093e-04 - accuracy: 0.9999 - val_loss: 1.6062 - val_accuracy: 0.8062\n",
            "Epoch 14/20\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 1.6524e-04 - accuracy: 0.9999 - val_loss: 1.6435 - val_accuracy: 0.8062\n",
            "Epoch 15/20\n",
            "438/438 [==============================] - 10s 22ms/step - loss: 1.6213e-04 - accuracy: 0.9999 - val_loss: 1.6815 - val_accuracy: 0.8048\n",
            "Epoch 16/20\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 1.6148e-04 - accuracy: 0.9999 - val_loss: 1.7202 - val_accuracy: 0.8054\n",
            "Epoch 17/20\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 1.6741e-04 - accuracy: 0.9999 - val_loss: 1.7603 - val_accuracy: 0.8045\n",
            "Epoch 18/20\n",
            "438/438 [==============================] - 9s 20ms/step - loss: 1.5958e-04 - accuracy: 0.9999 - val_loss: 1.8011 - val_accuracy: 0.8039\n",
            "Epoch 19/20\n",
            "438/438 [==============================] - 8s 19ms/step - loss: 1.7452e-04 - accuracy: 0.9999 - val_loss: 1.7909 - val_accuracy: 0.8034\n",
            "Epoch 20/20\n",
            "438/438 [==============================] - 9s 21ms/step - loss: 1.8004e-04 - accuracy: 0.9999 - val_loss: 1.8250 - val_accuracy: 0.8019\n",
            "110/110 - 1s - loss: 1.8250 - accuracy: 0.8019 - 637ms/epoch - 6ms/step\n",
            "\n",
            "Test accuracy after a total of 20 epochs: 80.19%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}